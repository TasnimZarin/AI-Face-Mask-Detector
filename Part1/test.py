# -*- coding: utf-8 -*-
"""finalized_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u7TCB_yegvdIOBOtn7JD7xq5tzkgQV45

## AI project/ phase 1

### Importing the libraries
"""

import os
from os.path import exists
from pathlib import Path
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from shutil import copyfile
import torchvision
from PIL import Image
import io
import random
import matplotlib.pyplot as plt
import numpy as np
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import random_split
from torch.utils.data import TensorDataset, ConcatDataset, DataLoader
import pandas as pd
from torchvision.transforms import ToTensor, Lambda
from torchvision.io import read_image
import matplotlib.pyplot as plt
import torch.optim as optim
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix
from skorch import NeuralNetClassifier
import sklearn

""" Here, we just set our working directory to the path including our dataset."""


"""### Defining a custom dataset for our images"""

class CustomImageDataset():
    def __init__(self, annotations_file, img_dir,
            transform=torchvision.transforms.Compose([
                transforms.ToPILImage(),
                transforms.Grayscale(num_output_channels=3),
                transforms.ToTensor(),
                #Resizing all of the imagesin the dataset to (240,240)
                transforms.Resize((240,240)),
                #Normalization using the mean and variance over the whole dataset
                transforms.Normalize((0.5352, 0.5352, 0.5352),(0.3009, 0.3009, 0.3009))]),
                 #Lambda function is used for turning the integer into a tensor
            target_transform=Lambda(lambda y: torch.zeros(5, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))):
        self.img_labels = pd.read_csv(annotations_file)   #Dataaset labels
        self.img_dir = img_dir      #Dataset image path     
        self.transform = transform   
        self.target_transform = target_transform
        

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        if(os.path.exists(img_path)):
            image = read_image(img_path)
            label = torch.tensor(int(self.img_labels.iloc[idx, 1]))
            if self.transform:
                image = self.transform(image)
            image.shape
            return image, label



"""### Augmentation technique for increasing the size of dataset
In this part, we selected a number of images in all of the classes except for the cloth mask class and we increased their number by using augmentation technique. We rotated theimages by 180 degrees which resulted in producing new data samples.
"""

class AugmentedDataset():
    def __init__(self, annotations_file, img_dir,
            transform=torchvision.transforms.Compose([
                transforms.ToPILImage(),
                transforms.Grayscale(num_output_channels=3),
                transforms.ToTensor(),
                transforms.Resize((240,240)),
                transforms.RandomRotation(degrees=180),#Augmentation
                transforms.RandomHorizontalFlip(p=1),#Augmentation
                #Normalization for all dataset using mean and varinace
                transforms.Normalize((0.5352, 0.5352, 0.5352),(0.3009, 0.3009, 0.3009))]),
            target_transform=Lambda(lambda y: torch.zeros(5, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))):
        self.img_labels = pd.read_csv(annotations_file) #Dataaset labels
        self.img_dir = img_dir   #Dataset image path
        self.transform = transform
        self.target_transform = target_transform
        

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        if(os.path.exists(img_path)):
            image = read_image(img_path)
            label = torch.tensor(int(self.img_labels.iloc[idx, 1]))
            if self.transform:
                image = self.transform(image)
            image.shape
            return image, label

"""### Spiliting defined dataset to train and test sets"""

batch_size = 16
validation_split = .2
shuffle_dataset = True
random_seed= 42   #Preventing from random events in each run

dataset=CustomImageDataset(annotations_file=r'G:\.shortcut-targets-by-id\1noXdisFl6MYE_w2qtCawV4fozNQDCP_I\COMP-6721(AI_project)\Submission\sample-label.csv', img_dir=r'G:\.shortcut-targets-by-id\1noXdisFl6MYE_w2qtCawV4fozNQDCP_I\COMP-6721(AI_project)\Submission\Sample images')
test_loader = torch.utils.data.DataLoader(dataset, batch_size,shuffle=False)


"""### Defining a function for getting mean and variance

This function helps to do the normalization over the dataset.
"""

def get_mean_and_std(dataloader):
    channels_sum, channels_squared_sum, num_batches = 0, 0, 0
    for data, _ in dataloader:
        channels_sum += torch.mean(data, dim=[0,2,3]) #Computing the mean
        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])
        num_batches += 1
    
    mean = channels_sum / num_batches

    
    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5 #Computing the standard deviation

    return mean, std

"""### Defining the CNN network
Here, we define our CNN network with 5 convolutional layers.
"""

classes = ('Cloth mask', 'N95 and FFP2', 'N95 and FFP2 with valve', 'Surgical mask','No mask') # 5 classes
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv_layer = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1), #First layer
            nn.BatchNorm2d(32),                 #Batch normalization
            nn.LeakyReLU(inplace=True),         #Leaky ReLU activation function
            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1), #Second layer
            nn.BatchNorm2d(32),                #Batch normalization
            nn.LeakyReLU(inplace=True),        #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2),     #Max pooling
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), #Third layer
            nn.BatchNorm2d(64),              #Batch normalization
            nn.LeakyReLU(inplace=True),      #Leaky ReLU activation function
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #Fourth layer
            nn.BatchNorm2d(64),             #Batch normalization
            nn.LeakyReLU(inplace=True),     #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2),    #Max pooling
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #Fifth layer
            nn.BatchNorm2d(64),            #Batch normalization
            nn.LeakyReLU(inplace=True),    #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2)    #Max pooling
          )

        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),   #0.1 dropout rate
            nn.Linear(57600, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(512, 5) #outputs = number of classes
          )

    def forward(self, x):
        # conv layers
        x = self.conv_layer(x)
        # flatten
        x = x.view(x.size(0), -1)
        #fc layer
        x = self.fc_layer(x)
        
        return x

"""### 5 fold cross validation
In this part, we are using 5 fold cross validation for improving the training process of our model. In each step, train set is divided to 80 percent and 20 percent for training and evaluation respectively.
"""
import torchvision.models as models
network = CNN()
network.load_state_dict(torch.load(r'G:\.shortcut-targets-by-id\1noXdisFl6MYE_w2qtCawV4fozNQDCP_I\COMP-6721(AI_project)\Submission\ourmodel.pth'))
network.eval()

"""### Evaluation
Computing the accuracy of the trained model on the testset
"""

with torch.no_grad():
  correct = 0
  total = 0

for images, labels in test_loader:
  outputs = network(images)
  _, predicted = torch.max(outputs.data, 1) #Computing the prediction of the model 
  total += labels.size(0)
  correct += (predicted == labels).sum().item() #Computing the number of correct predicted items
print('Test Accuracy of the model on the {} test images: {} %'.format(len(dataset),(correct / total) * 100))

"""### Plotting the confusion matrix, accuracy, precision, recall and f1 score"""

DEVICE = torch.device("cpu")
y_train = np.array([y for x, y in iter(dataset)])
torch.manual_seed(0)
net = NeuralNetClassifier(
    CNN,
    max_epochs=1,
    lr=1e-3, #Learning rate
    batch_size=16,
    optimizer=optim.Adam, #Using adam optimizer
    criterion=nn.CrossEntropyLoss,
    device=DEVICE
)
print(test_loader)
net.fit(test_loader, y=y_train)
y_pred = net.predict(dataset)  #Obtaining the predictions
y_test = np.array([y for x, y in iter(dataset)]) #Obtaining labels of testset
print("accuracy: ",accuracy_score(y_test, y_pred)) #accuracy
plot_confusion_matrix(net, testset, y_test.reshape(-1, 1)) #Confusion matrix
plt.show()

print("y_pred: ",y_pred)

precision = sklearn.metrics.precision_score(y_test, y_pred, pos_label='positive', average='micro') #Precision
print('Precision : %.3f %%' % (100.0 * precision))
recall = sklearn.metrics.recall_score(y_test, y_pred, pos_label='positive', average='micro') #Recall
print('Recall : %.3f %%' % (100.0 * recall))
f1_score = sklearn.metrics.f1_score(y_test, y_pred, pos_label='positive', average='micro') #F1_score
print('F1_score : %.3f %%' % (100.0 * f1_score))
