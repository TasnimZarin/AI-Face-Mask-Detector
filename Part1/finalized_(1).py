# -*- coding: utf-8 -*-
"""finalized (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15CfCPsCHhh5YE1lZt7oMFU4WmLJUVtE6

## AI project/ phase 1

### Importing the libraries
"""

import os
from os.path import exists
from pathlib import Path
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from shutil import copyfile
import torchvision
from PIL import Image
import io
import random
import matplotlib.pyplot as plt
import numpy as np
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import random_split
from torch.utils.data import TensorDataset, ConcatDataset, DataLoader
import pandas as pd
from torchvision.transforms import ToTensor, Lambda
from torchvision.io import read_image
import matplotlib.pyplot as plt
import torch.optim as optim
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix
from skorch import NeuralNetClassifier
import sklearn

""" Here, we just set our working directory to the path including our dataset."""



"""### Defining a custom dataset for our images"""

class CustomImageDataset():
    def __init__(self, annotations_file, img_dir,
            transform=torchvision.transforms.Compose([
                transforms.ToPILImage(),
                transforms.Grayscale(num_output_channels=3),
                transforms.ToTensor(),
                #Resizing all of the imagesin the dataset to (240,240)
                transforms.Resize((240,240)),
                #Normalization using the mean and variance over the whole dataset
                transforms.Normalize((0.5159, 0.5159, 0.5159),(0.3149, 0.3149, 0.3149))]),
                 #Lambda function is used for turning the integer into a tensor
            target_transform=Lambda(lambda y: torch.zeros(6, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform
        

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        if(os.path.exists(img_path)):
            image = read_image(img_path)
            label = torch.tensor(int(self.img_labels.iloc[idx, 1]))
            if self.transform:
                image = self.transform(image)

            image.shape
            return image, label

"""### Augmentation technique for increasing the size of dataset"""

class AugmentedDataset():
    def __init__(self, annotations_file, img_dir,
            transform=torchvision.transforms.Compose([
                transforms.ToPILImage(),
                transforms.Grayscale(num_output_channels=3),
                transforms.ToTensor(),
                transforms.Resize((240,240)),
                transforms.RandomRotation(degrees=180),#Augmentation
                transforms.RandomHorizontalFlip(p=1),#Augmentation
                #transforms.functional.adjust_contrast(image,contrast_factor=3.8),#Augmentation
                transforms.Normalize((0.5159, 0.5159, 0.5159),(0.3149, 0.3149, 0.3149))]),#Normalization for all dataset
            target_transform=Lambda(lambda y: torch.zeros(6, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform
        

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        if(os.path.exists(img_path)):
          image = read_image(img_path)
          label = torch.tensor(int(self.img_labels.iloc[idx, 1]))
          #print(label)
          if self.transform:
            image = self.transform(image)
          image.shape
          #plt.imshow(image.permute((1,2,0)))
          #plt.show()
          #print(idx)
          return image, label

"""### Spiliting defined dataset to train and test sections"""

batch_size = 16
validation_split = .2
shuffle_dataset = True
random_seed= 42   #Preventing from random events in each run
dataset1=CustomImageDataset(annotations_file=r'G:\My Documents\6721\labels.csv', img_dir=r'G:\My Documents\6721\dataset')
dataset2=AugmentedDataset(annotations_file=r'G:\My Documents\6721\label_aug.csv', img_dir=r'G:\My Documents\6721\dataset_aug')
dataset = ConcatDataset([dataset1, dataset2]) #Combining our initial dataset with the augmented one
m = len(dataset)
# Spilitting dataset to trainset and testset randomly
trainset, testset = random_split(dataset, [int(np.floor(m - m * 0.2)), int(np.ceil(m * 0.2))])
train_loader = torch.utils.data.DataLoader(trainset, batch_size,shuffle=True)
test_loader = torch.utils.data.DataLoader(testset, batch_size,shuffle=False)

"""### Defining a function for getting mean and variance """

#This function helps to do the normalization over the dataset.

def get_mean_and_std(dataloader):
    channels_sum, channels_squared_sum, num_batches = 0, 0, 0
    for data, _ in dataloader:
        channels_sum += torch.mean(data, dim=[0,2,3])
        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])
        num_batches += 1
    
    mean = channels_sum / num_batches

    
    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5

    return mean, std

"""### Defining the CNN network"""

classes = ('Cloth mask', 'N95 and FFP2', 'N95 and FFP2 with valve', 'Surgical mask','No mask')
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv_layer = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1), #First layer
            nn.BatchNorm2d(32),                 #Batch normalization
            nn.LeakyReLU(inplace=True),         #Leaky ReLU activation function
            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1), #Second layer
            nn.BatchNorm2d(32),                #Batch normalization
            nn.LeakyReLU(inplace=True),        #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2),     #Max pooling
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), #Third layer
            nn.BatchNorm2d(64),              #Batch normalization
            nn.LeakyReLU(inplace=True),      #Leaky ReLU activation function
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #Fourth layer
            nn.BatchNorm2d(64),             #Batch normalization
            nn.LeakyReLU(inplace=True),     #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2),    #Max pooling
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #Fifth layer
            nn.BatchNorm2d(64),            #Batch normalization
            nn.LeakyReLU(inplace=True),    #Leaky ReLU activation function
            nn.MaxPool2d(kernel_size=2, stride=2)    #Max pooling
          )

        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(57600, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(512, 5)
          )

    def forward(self, x):
        # conv layers
        x = self.conv_layer(x)
        # flatten
        x = x.view(x.size(0), -1)
        #fc layer
        x = self.fc_layer(x)
        
        return x

# Define the K-fold Cross Validator

from sklearn.model_selection import KFold
k_folds = 5
num_epochs = 1
loss_function = nn.CrossEntropyLoss()
  
  # For fold results
results = {}
kfold = KFold(n_splits=k_folds, shuffle=True)
    
# Start print
print('--------------------------------')

# K-fold Cross Validation model evaluation
for fold, (train_ids, test_ids) in enumerate(kfold.split(trainset)):
    
# Print
    print(f'FOLD {fold}')
    print('--------------------------------')
    
    # Sample elements randomly from a given list of ids, no replacement.
    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)
    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)
    
    # Define data loaders for training and testing data in this fold
    trainloader = torch.utils.data.DataLoader(
                      trainset, 
                      batch_size=32, sampler=train_subsampler)
    testloader = torch.utils.data.DataLoader(
                      trainset,
                      batch_size=32, sampler=test_subsampler)
    
    # Init the neural network
    network = CNN()
    #network.apply(reset_weights)
    
    # Initialize optimizer
    optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)
    
    # Run the training loop for defined number of epochs
    for epoch in range(0, num_epochs):

      # Print epoch
        print(f'Starting epoch {epoch+1}')

      # Set current loss value
        current_loss = 0.0

      # Iterate over the DataLoader for training data
        for i, data in enumerate(trainloader, 0):
        
        # Get inputs
            inputs, targets = data
        
        # Zero the gradients
            optimizer.zero_grad()
        
        # Perform forward pass
            outputs = network(inputs)
        
        # Compute loss
            loss = loss_function(outputs, targets)
        
        # Perform backward pass
            loss.backward()
        
        # Perform optimization
            optimizer.step()
        
        # Print statistics
            current_loss += loss.item()
            if i % 267 == 266:
                print('Loss after mini-batch %5d: %.3f' %(i + 1, current_loss / 267))
                current_loss = 0.0
            
    # Process is complete.
        print('Training process has finished. Saving trained model.')

    # Print about testing
        print('Starting testing')
    
    # Saving the model
        save_path = r'G:\My Documents\6721'
        torch.save(network.state_dict(), os.path.join(save_path,"ourmodel.pth"))

    # Evaluationfor this fold
        correct, total = 0, 0
        with torch.no_grad():

      # Iterate over the test data and generate predictions
            for i, data in enumerate(testloader, 0):
        

        # Get inputs
                inputs, targets = data

        # Generate outputs
                outputs = network(inputs)

        # Set total and correct
                _, predicted = torch.max(outputs.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()

      # Print accuracy
            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))
            print('--------------------------------')
            results[fold] = 100.0 * (correct / total)
    
  # Print fold results
print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')
print('--------------------------------')
sum = 0.0
for key, value in results.items():
    print(f'Fold {key}: {value} %')
    sum += value
print(f'Average: {sum/len(results.items())} %')

network.eval()
with torch.no_grad():
  correct = 0
  total = 0

for images, labels in test_loader:
  outputs = network(images)
  _, predicted = torch.max(outputs.data, 1)
  total += labels.size(0)
  correct += (predicted == labels).sum().item()
print('Test Accuracy of the model on the {} test images: {} %'.format(len(testset),(correct / total) * 100))

DEVICE = torch.device("cpu")
y_train = np.array([y for x, y in iter(trainset)])
print("y_train", y_train)
torch.manual_seed(0)
net = NeuralNetClassifier(
    CNN,
    max_epochs=1,
    #iterator_train__num_workers=4,
    #iterator_valid__num_workers=4,
    lr=1e-3,
    batch_size=16,
    optimizer=optim.Adam,
    criterion=nn.CrossEntropyLoss,
    device=DEVICE
)
net.fit(trainset, y=y_train)
y_pred = net.predict(testset)
y_test = np.array([y for x, y in iter(testset)])
print("accuracy: ",accuracy_score(y_test, y_pred))
plot_confusion_matrix(net, testset, y_test.reshape(-1, 1))
plt.show()

print("y_pred: ",y_pred)

precision = sklearn.metrics.precision_score(y_test, y_pred, pos_label='positive', average='micro')
print('Precision : %.3f %%' % (100.0 * precision))
#print("precision:{} %0.3f %%" % precision*100)
recall = sklearn.metrics.recall_score(y_test, y_pred, pos_label='positive', average='micro')
#print("recall: {} %0.3f %%" % recall*100)
print('Recall : %.3f %%' % (100.0 * recall))
f1_score = sklearn.metrics.f1_score(y_test, y_pred, pos_label='positive', average='micro')
#print("f1_score: {} %0.3f", f1_score)
print('F1_score : %.3f %%' % (100.0 * f1_score))

